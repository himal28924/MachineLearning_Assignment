{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression: Optimization of Long-Term Correction of Wind Data Using Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment Description**\n",
    "\n",
    "In this assignment, you will work with realistic data from the wind industry. Vestas, a leading global company in wind energy, is interested in optimizing their methods for generating long-term corrected (LTC) wind data, which are used for planning the locations of new wind farms.\n",
    " \n",
    "You will have access to two types of time series data:\n",
    " 1) Mast time series data that represent the wind conditions at a specific location based on measurements from a wind measuring mast. These data usually cover a period of 1-4 years.\n",
    " 2) Meso time series data that are based on weather measurement models and cover more than 20 years. While these data are less precise and don't exactly match the specific location, they provide a longer historical context.\n",
    "\n",
    "Note that the mast data for this project is significantly longer than \"typical\" mast data. This allows cutting the data into training and test sets (or training, validation and test sets). Each set should cover all four seasons.\n",
    "\n",
    "Your task is to develop a model using regression techniques that can generate LTC wind data. This LTC time series should be long, like the meso time series, but also give an accurate description of the wind conditions at the specific location.\n",
    "\n",
    "**Objectives and Purpose**\n",
    " \n",
    "The purpose of the assignment is to assess whether regression could be used instead of neural networks, which could potentially save time and money as it is generally quicker to perform a regression than to train a neural network. And the main objective is thus to develop a regression model that can generate LTC time series that are both accurate and cost-effective.\n",
    "\n",
    "**Requirements**\n",
    "1. **Data preprocessing:** You must handle large datasets and perform necessary data preprocessing tasks. This includes dealing with missing values, handling outliers, and scaling data appropriately for the chosen regression technique.\n",
    "\n",
    "    a. Consider the appropriate intervals for wind speeds and wind directions. No negative wind speeds are allowed, and wind directions should be in an appropriate interval (e.g. [0; 360[ degrees).\n",
    "\n",
    "    b. Select which ws / wd signals to use. Signals at higher altitude are generally better, but it is even more important to have proper coverage of all seasons.\n",
    "\n",
    "    c. Find the meso-signals closest in height to the mast-data-signal you are using. Or interpolate the values between 2 or more meso-signals to get the values at the exact mast-signal-height.\n",
    "\n",
    "    d. Convert the mast data from DK time to UTC time (corresponding to the time zone used in the meso data). Remember to account for summer-time in DK.\n",
    "    \n",
    "    e. Resample the mast dataset to have the same frequency as the meso data. The meso data has one record for each hour, the mast data has one record for each 10 min.\n",
    "\n",
    "        i. Note: You should not convert the ws / wd signals to vector-quantities and use those for the resampling. Resample the ws and wd signal individually instead. The turbines “yaw” to always point toward the incoming wind, so the interesting value is the wind speed and not the wind velocity.  \n",
    "        ii. Be careful when resampling the wind directions. You don’t want the average of 0 degrees and 359 degrees to become ~180 degrees :-)\n",
    "\n",
    "    f. Find the overlapping timestamps between the meso data and the resampled mast data. You only want to consider data in this overlapping time period in your training.\n",
    "\n",
    "2. **Exploratory analysis:** You must do an exploratory analysis of the data. This includes presenting the data in tables and graphs, study and describe features of interest, as well as correlation analysis. Wind speeds typically follow a Weibull-distributions. Try fitting a Weibull distribution to the mast data, the resampled mast data and the meso-data. \n",
    "3. **Model Development:** Use appropriate machine learning principles and methodologies, including model training and testing and perhaps validation, cross-validation, and leave-one-out. You should apply and interpret regression models effectively for this task.\n",
    "4. **Model Evaluation:** Evaluate the developed model using appropriate metrics such as Mean Squared Error (MSE), R-squared (R²), etc. The evaluation should give an indication of the usefulness of your model in predicting wind conditions accurately. \n",
    "In addition to calculating the above metric for your predicted time series, also consider comparing the distributions of the wind speeds in the predicted and the actual (resampled) mast data. That is, calculate the Weibull A- and k-parameters for both distributions, and find the error in these between your fit and the true data. \"Error-in-A\" and \"Error-in-k\" are the most used quantities to evaluate the long term correction process in the wind industry :-)\n",
    "5. **Documentation and Presentation:** Clearly document the steps, methodologies, and tools you used during the process. Present the results of your model in a clear and effective manner. This documentation should be comprehensive enough for someone to replicate your process and understand your results. Hand-in as one Jupyter Notebook.\n",
    "\n",
    "\n",
    "**Some additional comments**\n",
    "\n",
    "They (Vestas) have also tried running their own LTC algorithm on some of the data (they chose the 77m wind speed and wind direction signals from the Risø dataset), and this yielded good results. They assumed that the data was in Danish time, so they believe that is the case.\n",
    "\n",
    "As you can see, there is quite a focus on wind speeds (as they determine the amount of power produced). However, they know that their neural network operates by training on the different components of wind speed separately (meaning training one network on the x-component of the wind and another network on the y-component of the wind) and then combining them at the end. You may consider this method too. They are not sure if it yields better performance than training on wind speed and wind direction separately...but if time permits, give it a go.\n",
    "\n",
    "**About the data**\n",
    "\n",
    "The mast datasets are in netCDF format. It's quite easy to work with in Python (not sure if you've used it before?). In one of the folders, a test.py file is included that demonstrate how to load the dataset and access the most relevant mast signals.\n",
    "\n",
    "The mast data has a measurement frequency of 10 minutes, while the meso data has a frequency of 1 hour. Therefore, you will need to resample the mast data to a 1-hour frequency before you can use it (see requirement 1.e above). Vestas does the same with their data. As mentioned you should be careful when resampling the angles so that the average of 0 degrees (north) and 359 degrees doesn't end up being approximately 180 degrees.\n",
    "\n",
    "The data is publicly available. You can read more about it here:\n",
    "\n",
    "*Risø:*\n",
    "\n",
    "https://gitlab.windenergy.dtu.dk/fair-data/winddata-revamp/winddata-documentation/-/blob/kuhan-master-patch-91815/risoe_m.md\n",
    "\n",
    "Data: https://data.dtu.dk/articles/dataset/Wind_resource_data_from_the_tall_Ris_met_mast/14153204 (this is the \"DOI\"-link from the description)\n",
    "\n",
    "\n",
    "*Børglum:*\n",
    "\n",
    "https://gitlab.windenergy.dtu.dk/fair-data/winddata-revamp/winddata-documentation/-/blob/kuhan-master-patch-91815/borglum.md\n",
    "\n",
    "Data: https://data.dtu.dk/articles/dataset/Resource_data_from_the_Borglum_mast/14153231\n",
    "\n",
    "The two meso datasets come from Vestas' climate library, and the meso data is in UTC time. They don't think you need anything other than the \"wind speed\" (WSP) and \"wind direction\" (WDIR) signals. They believe it's most appropriate to either use the height closest to the mast height (for example, if you're using the wind speed signal ws125 and the wind direction signal wd125 from the Risø dataset, you should use WSP120 and WDIR120 from the meso dataset) or use multiple signals and interpolate to the desired height (125m) (see the requirements above).\n",
    "\n",
    "**Final comments**\n",
    "\n",
    "In a perfect world, you can do all of the above. The assignment is \"free\" in the sense that you should give the above a go and do your best. Remember, there is no right answer. This assignment is a real-world machine learning task and not a \"made-up\" school task. There are software engineers at Vestas working on exactly the same task (albeit with a different dataset, which they arent' allowed to share with us). But try to discuss the problem in your group and distribute the work among you. You can even collaborate with other groups or find inspiration in their approach.\n",
    "\n",
    "And remember. These portfolio assignments are not meant as \"learn stuff in class and apply to assignment\" - they are part of the learning process, and not simply a documentation of what you have learned. They should be seen as \"learning by doing\"-type assignments.\n",
    "\n",
    "In session 5, we will do a Q/A if you have any questions. But as mentioned, try to give it a go. "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import folium\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:26:45.106485700Z",
     "start_time": "2023-11-13T21:26:45.094972700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Importing data\n",
    "file_path_risoe = 'Data/Risoe/risoe_m_all.nc'\n",
    "file_paths_borglum = 'Data/Borglum/borglum_all.nc'\n",
    "signals_risoe = ['ws77', 'wd77', 'ws125', 'wd125']\n",
    "signals_borglum = ['ws32', 'wd32']\n",
    "\n",
    "base_date_borglum = datetime(1997, 12, 11, 16, 5, 0)\n",
    "base_date_risoe = datetime(1995, 11, 20, 16, 25, 0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:09:07.237189800Z",
     "start_time": "2023-11-13T21:09:07.160999300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Geting the Risoe data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in the netCDF file:\n",
      "time\n",
      "ws44\n",
      "ws44_qc\n",
      "ws77\n",
      "ws77_qc\n",
      "ws125\n",
      "ws125_qc\n",
      "wd77\n",
      "wd77_qc\n",
      "wd125\n",
      "wd125_qc\n",
      "t003\n",
      "t003_qc\n",
      "t044\n",
      "t044_qc\n",
      "t118\n",
      "t118_qc\n",
      "td01\n",
      "td01_qc\n",
      "rain\n",
      "rain_qc\n",
      "press\n",
      "press_qc\n",
      "rhum\n",
      "rhum_qc\n",
      "grad\n",
      "grad_qc\n",
      "time for Risoe:\n",
      " ['1995-11-20 16:25:00', '1995-11-20 16:35:00', '1995-11-20 16:45:00', '1995-11-20 16:55:00', '1995-11-20 17:05:00', '1995-11-20 17:15:00', '1995-11-20 17:25:00', '1995-11-20 17:35:00', '1995-11-20 17:45:00', '1995-11-20 17:55:00'] - 2007-12-31 23:56:00\n",
      "ws77:\n",
      " [3.36 3.05 3.59 3.87 4.74 4.91 4.98 5.39 5.76 5.52] - [8.14 8.71 6.82 7.26 7.24 6.04 6.97 8.17 6.66]\n",
      "wd77:\n",
      " [205. 205. 204. 202. 201. 206. 203. 203. 193. 200.] - [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ws125:\n",
      " [3.04 3.17 3.64 3.77 4.28 4.91 5.35 5.58 5.75 5.38] - [nan nan nan nan nan nan nan nan nan]\n",
      "wd125:\n",
      " [208. 214. 209. 209. 212. 213. 210. 206. 207. 205.] - [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the Risoe dataset:\n",
    "risoe_dataset = nc.Dataset(file_path_risoe, 'r')\n",
    "\n",
    "# List the variables in the dataset\n",
    "print(\"Variables in the netCDF file:\")\n",
    "for var_name in risoe_dataset.variables:\n",
    "    print(var_name)\n",
    "\n",
    "risoe_dataset_time_minutes = np.array(risoe_dataset.variables['time'])\n",
    "\n",
    "# Convert time values to timestamp strings\n",
    "time = []\n",
    "for minutes in risoe_dataset_time_minutes:\n",
    "\ttime_delta = timedelta(minutes=int(minutes))\n",
    "\ttimestamp = base_date_risoe + time_delta\n",
    "\ttime.append(timestamp.strftime('%Y-%m-%d %H:%M:%S'))\n",
    " \n",
    "print(f\"time for Risoe:\\n {time[:10]} - {time[-1]}\")\n",
    "\n",
    "for signal in signals_risoe:\n",
    "\tvalues = np.array(risoe_dataset.variables[signal])\n",
    "\tprint(f'{signal}:\\n {values[:10]} - {values[-10:-1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:10:02.388516300Z",
     "start_time": "2023-11-13T21:09:59.227208400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Geting the Borglum data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in the netCDF file:\n",
      "time\n",
      "ws44\n",
      "ws44_qc\n",
      "ws77\n",
      "ws77_qc\n",
      "ws125\n",
      "ws125_qc\n",
      "wd77\n",
      "wd77_qc\n",
      "wd125\n",
      "wd125_qc\n",
      "t003\n",
      "t003_qc\n",
      "t044\n",
      "t044_qc\n",
      "t118\n",
      "t118_qc\n",
      "td01\n",
      "td01_qc\n",
      "rain\n",
      "rain_qc\n",
      "press\n",
      "press_qc\n",
      "rhum\n",
      "rhum_qc\n",
      "grad\n",
      "grad_qc\n",
      "\n",
      "Time for Borglum:\n",
      " ['1997-12-11 16:05:00', '1997-12-11 16:15:00', '1997-12-11 16:25:00', '1997-12-11 16:35:00', '1997-12-11 16:45:00', '1997-12-11 16:55:00', '1997-12-11 17:05:00', '1997-12-11 17:15:00', '1997-12-11 17:25:00', '1997-12-11 17:35:00'] - 2010-01-21 23:36:00\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ws32'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 21\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mTime for Borglum:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime[:\u001B[38;5;241m10\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m signal \u001B[38;5;129;01min\u001B[39;00m signals_borglum:\n\u001B[1;32m---> 21\u001B[0m \tvalues \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43mborglum_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvariables\u001B[49m\u001B[43m[\u001B[49m\u001B[43msignal\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[0;32m     22\u001B[0m \t\u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msignal\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalues[:\u001B[38;5;241m10\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalues[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m10\u001B[39m:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'ws32'"
     ]
    }
   ],
   "source": [
    "# Get the Borglum dataset:\n",
    "borglum_dataset = nc.Dataset(file_path_risoe, 'r')\n",
    "\n",
    "# List the variables in the dataset\n",
    "print(\"Variables in the netCDF file:\")\n",
    "for var_name in borglum_dataset.variables:\n",
    "    print(var_name)\n",
    "\n",
    "borglum_dataset_time_minutes = np.array(borglum_dataset.variables['time'])\n",
    "\n",
    "# Convert time values to timestamp strings\n",
    "time = []\n",
    "for minutes in borglum_dataset_time_minutes:\n",
    "\ttime_delta = timedelta(minutes=int(minutes))\n",
    "\ttimestamp = base_date_borglum + time_delta\n",
    "\ttime.append(timestamp.strftime('%Y-%m-%d %H:%M:%S'))\n",
    " \n",
    "print(f\"\\nTime for Borglum:\\n {time[:10]} - {time[-1]}\")\n",
    "\n",
    "for signal in signals_borglum:\n",
    "\tvalues = np.array(borglum_dataset.variables[signal])\n",
    "\tprint(f'{signal}:\\n {values[:10]} - {values[-10:-1]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:09:13.697974300Z",
     "start_time": "2023-11-13T21:09:10.563903200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
